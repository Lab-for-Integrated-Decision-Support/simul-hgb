---
title: "04_Temporal_Analysis"
author: "Adam Dziorny"
date: '2022-10-19'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

The purpose of this markdown is to describe the temporal components of simultaneous Hgb pairs. This is in direct response to the reviewer's calls for examining "change over time" of Hgb variables. In this markdown we look at counts of repeated measures per patient (which we have been filtering out during sensitivity analysis in `02` and `03`), and we look at change over time across tests.

## Initialize

First we load the necessary packages:

```{r, warning=FALSE}
suppressPackageStartupMessages({
  
  # Data frame manipulation
  require(dplyr)
  
  # Graphics and output
  require(ggplot2)

  # Tables
  require(knitr)
  require(kableExtra)
  
  # Error grid point allocation
  require(ptinpoly)

})
```

Ensure the environmental variables are specified:

```{r}
if (Sys.getenv('PICU_LAB_DATA_PATH') == '' |
    Sys.getenv('PICU_LAB_IMG_PATH') == '' |
    Sys.getenv('PICU_LAB_IN_FILE') == '' |
    Sys.getenv('PICU_LAB_SITE_NAME') == '' |
    Sys.getenv('PICU_LAB_RUN_DATE') == '')
  stop('Missing necessary environmental variables - see README.md')

cat(sprintf('Site: %s\n', Sys.getenv('PICU_LAB_SITE_NAME')))
```

Specify the run date:

```{r}
run.date <- Sys.getenv('PICU_LAB_RUN_DATE')

cat(sprintf('Run Date: %s\n', run.date))
```

## Data Input

Load data from the `DATA_PATH` with the associated `IN_FILE`, adding a file separator between them. This should result in loading two data frames: `cohort.df` and `labs.df`.

```{r}
load(
  file = file.path(
    Sys.getenv('PICU_LAB_DATA_PATH'),
    Sys.getenv('PICU_LAB_IN_FILE')
  )
)
```

## Set Parameters

We will utilize several sensitivity analyses in this markdown - these should be identical to the sensitivity indicators in the markdown `02_Analytic_Accuracy.Rmd`. No changes should be made to these parameters - only additions for more sensitivity parameters.

```{r}
# The primary cutoff value between collection times (in minutes) to 
# determine "simultaneous"
primary.cutoff <- 15. 

# Sensitivity analysis list
sens.cutoffs <- c(1., 30., 90.)

# Time difference max between successive paired (simultaneously acquired) labs
time.diff.max <- 6. * 60. # Note this is in minutes
```

## Join

Once again the below join function is a copy of the function used in `02_Analytic_Accuracy.Rmd`. No changes should be made to this version - make changes to the prior version, re-test within that script, and then copy here. After development, this will be moved to a package.

```{r}
#'
#' @title Create Paired Dataset
#' 
#' @description Creates a dataset of paired simultaneous lab values
#'
#' @param labs.df The labs data frame
#' @param cohort.df The cohort data frame, needed for PAT_KEY and DEPT
#' @param PN A two-element list of PROC_NAMEs to join
#' @param time.diff The max time difference (min) between collected times
#' @param CN The COMP_NAME to join [Default: 'Hgb']
#' @param multi.per.pt If FALSE, limit to first result per patient, otherwise 
#'     if TRUE [Default], allow all
#'     
#' @returns The resulting joined data frame
#'
createPairedDataset <- function (labs.df, cohort.df, PN, time.diff, 
                           CN = 'Hgb', multi.per.pt = T) {
  
  # First we filter to remove the non-numeric rows
  filter.df <- 
    labs.df %>%
    dplyr::filter(!is.na(NUM_VAL) & NUM_VAL != 9999999.) %>%
    dplyr::filter(COMP_NAME == CN)
  
  cat(sprintf('Number of component numeric rows in input data frame: %d\n',
              nrow(filter.df)))
  
  # Join to get PAT_KEY and DEPT, used in subsequent filtering
  keyed.df <- 
    dplyr::left_join(
      x = filter.df,
      y = cohort.df %>% 
        dplyr::select(ENC_KEY, PAT_KEY, DEPT),
      by = c('ENC_KEY')
    )
  
  # Now we filter by PN and join to create full data frame
  joined.df <-
    dplyr::inner_join(
      x = keyed.df %>%
        dplyr::filter(PROC_NAME == PN[1]) %>%
        dplyr::select(ENC_KEY, PAT_KEY, ORDER_PROC_KEY, 
                      DEPT, COLLECTED_DT, RESULT_DT, NUM_VAL, AGE_PROC),
      y = keyed.df %>%
        dplyr::filter(PROC_NAME == PN[2]) %>%
        dplyr::select(ENC_KEY, PAT_KEY, ORDER_PROC_KEY,
                      DEPT, COLLECTED_DT, RESULT_DT, NUM_VAL),
      by = c('ENC_KEY', 'PAT_KEY', 'DEPT'),
      suffix = c('.x', '.y')
    ) 
  
  # Join using base R, by column number
  #   [[5]] is PN[1] COLLECTED_DT
  #   [[10]] is PN[2] COLLECTED_DT
  joined.df$COLL_TIME_DIFF_MIN <-
    as.numeric(joined.df[[5]] - joined.df[[10]], units = 'mins')
 
  # Apply the cutoff time
  cutoff.df <- 
    joined.df %>%
    dplyr::filter(abs(COLL_TIME_DIFF_MIN) < time.diff)
  
  cat(sprintf('Number of paired, simultaneous values meeting cutoff: %d\n',
              nrow(cutoff.df)))
    
  # Ensure that each first PROC_NAME order is only used once - meaning that  
  # each ORDER_PROC_KEY.x should be unique
  unique.x.df <- 
    cutoff.df%>%
    dplyr::arrange(ORDER_PROC_KEY.x, COLL_TIME_DIFF_MIN) %>%
    dplyr::group_by(ORDER_PROC_KEY.x) %>%
    dplyr::summarize(
      ORDER_PROC_KEY.y   = first( ORDER_PROC_KEY.y   ),
      DEPT               = first( DEPT               ),
      COLLECTED_DT.x     = first( COLLECTED_DT.x     ),
      RESULT_DT.x        = first( RESULT_DT.x        ),
      NUM_VAL.x          = first( NUM_VAL.x          ),
      COLLECTED_DT.y     = first( COLLECTED_DT.y     ),
      RESULT_DT.y        = first( RESULT_DT.y        ),
      NUM_VAL.y          = first( NUM_VAL.y          ),
      COLL_TIME_DIFF_MIN = first( COLL_TIME_DIFF_MIN ),
      AGE_PROC           = first( AGE_PROC           ),
      ENC_KEY            = first( ENC_KEY            ),
      PAT_KEY            = first( PAT_KEY            )
    ) %>%
    dplyr::ungroup()

  cat(sprintf('Number of non-duplicated first PROC_NAME rows: %d\n',
              nrow(unique.x.df)))
    
  # Similarly, ensure that each second PROC_NAME order is being used just once
  # (i.e., that ORDER_PROC_KEY.y is not duplicated)
  non.dup.df <-
    unique.x.df %>%
    dplyr::arrange(ORDER_PROC_KEY.y, COLL_TIME_DIFF_MIN) %>%
    dplyr::group_by(ORDER_PROC_KEY.y) %>%
    dplyr::summarize(
      ORDER_PROC_KEY.x   = first( ORDER_PROC_KEY.x   ),
      DEPT               = first( DEPT               ),
      COLLECTED_DT.x     = first( COLLECTED_DT.x     ),
      RESULT_DT.x        = first( RESULT_DT.x        ),
      NUM_VAL.x          = first( NUM_VAL.x          ),
      COLLECTED_DT.y     = first( COLLECTED_DT.y     ),
      RESULT_DT.y        = first( RESULT_DT.y        ),
      NUM_VAL.y          = first( NUM_VAL.y          ),
      COLL_TIME_DIFF_MIN = first( COLL_TIME_DIFF_MIN ),
      AGE_PROC           = first( AGE_PROC           ),      
      ENC_KEY            = first( ENC_KEY            ),
      PAT_KEY            = first( PAT_KEY            )
    ) %>%
    dplyr::ungroup()
  
  cat(sprintf('Number of non-duplicated second PROC_NAME rows: %d\n',
              nrow(non.dup.df)))
    
  # Do we limit by one per patient?
  if (!multi.per.pt) {
    per.pt.df <-
      non.dup.df %>%
      # Sort by PAT_KEY and the first COLLECTED DT
      dplyr::arrange(PAT_KEY, COLLECTED_DT.x) %>%
      # Group by PAT_KEY and add a "LINE" number 
      dplyr::group_by(PAT_KEY) %>%
      dplyr::mutate(
        PAT_LINE = row_number()
      ) %>%
      # Ungroup
      dplyr::ungroup() %>%
      # Filter for lines == 1 only
      dplyr::filter(PAT_LINE == 1) %>%
      dplyr::select(-PAT_LINE)
  } else {
    per.pt.df <- non.dup.df
  }
  
  cat(sprintf('Number of paired, simultaneous values: %d\n',
              nrow(per.pt.df)))
  
  cat(sprintf('Number of duplicated ORDER_PROC_KEY.x values: %d\n',
              sum(duplicated(per.pt.df$ORDER_PROC_KEY.x))))
  
  return(per.pt.df)
}
```

First we create the CBC - BG dataset using the primary cutoff value, and include all pairs per patient.

```{r}
cbc.bg <- createPairedDataset(
  labs.df = labs.df, 
  cohort.df = cohort.df,
  PN = c('CBC', 'BG'), 
  CN = 'Hgb',
  time.diff = primary.cutoff,
  multi.per.pt = T
)
```

## Analysis

In this section we complete the temporal analysis. 

### Counts

First we look at the number of results per patient, and the time differences between paired results (for the same patient).

```{r}
#'
#' @title Describe Repeated Pairs
#' 
#' @description Describes counts of repeated pairs and time differences between pairs
#' 
#' @param paired.df The data frame of simultaneous (paired) results
#' @param to.print If TRUE, prints results [Default]
#' @param to.return If TRUE, returns results [Default]
#'
describeRepeatedPairs <- function (paired.df, to.print = T, to.return = T) {
  
  # Identify the counts of simultaneous labs per patient
  counts.per.enc <-
    paired.df %>%
    dplyr::group_by(ENC_KEY) %>%
    dplyr::count()
  
  if (to.print) {
    cat(sprintf('Summary of counts of pairs per patient:\n'))
    print(summary(counts.per.enc$n))
  }
  
  # Plot a histogram of counts per patient
  p.counts <-
    counts.per.enc %>%
    dplyr::filter(n > quantile(counts.per.enc$n, probs = c(0.01)) &
                    n < quantile(counts.per.enc$n, probs = c(0.99))) %>%
    ggplot() +
    geom_histogram(aes(x = n), bins = 40) +
    xlab('Number of Simultaneous (Paired) Labs Per Encounter') +
    ylab('Count') +
    theme_bw()
  
  if (to.print)
    print(p.counts)
  
  # What is the time difference between results for each patient?
  time.diff.per.enc <-
    paired.df %>%
    dplyr::arrange(ENC_KEY, COLLECTED_DT.x) %>%
    dplyr::group_by(ENC_KEY) %>%
    dplyr::mutate(
      DIFF_ENC = ENC_KEY == lag(ENC_KEY),
      TIME_DIFF = as.numeric(
        COLLECTED_DT.x - lag(COLLECTED_DT.x),
        units = 'mins'
      )
    ) %>%
    dplyr::filter(!is.na(DIFF_ENC)) %>%
    dplyr::ungroup()
  
  if (to.print) {
    cat(sprintf('Time diff (in Hours):\n'))
    print(summary(time.diff.per.enc$TIME_DIFF / 60.))
  }
  
  # Plot a histogram of the time difference, between 1st and 99th percentile
  p.time.diff <-
    time.diff.per.enc %>%
    dplyr::filter(TIME_DIFF > quantile(time.diff.per.enc$TIME_DIFF, probs = c(0.01)) &
                    TIME_DIFF < quantile(time.diff.per.enc$TIME_DIFF, probs = c(0.99))) %>%
    ggplot() +
    geom_histogram(aes(x = TIME_DIFF / 60.), bins = 40) +
    xlab('Time Between Successive Simultaneous (Paired) Labs, Per Enc (Hours)') +
    ylab('Count') +
    theme_bw()
  
  if (to.print)
    print(p.time.diff)
  
  if (to.return)
    return(list(
      #time.diff = time.diff.per.enc,
      p.time.diff = p.time.diff,
      #counts.per.enc = counts.per.enc,
      p.counts = p.counts
    ))
}
```

Now run the description function on the `cbc.bg` paired data frame:

```{r}
res.cbc.bg.pairs <- 
  describeRepeatedPairs(
    paired.df = cbc.bg, 
    to.print = T, 
    to.return = T
  )
```

### Change Comparison

Reviewers specifically requested an analysis of change (per procedure) - the change in CBC Hgb compared to the change in BG Hgb, for example. The change plot is based on this reference: <https://pubmed.ncbi.nlm.nih.gov/20736431/>

```{r}
#'
#' @title Calculate Change Comparison
#' 
#' @description Generates Delta Error Grid and Percents by Zone
#' 
#' @param paired.df The data frame of paired simultaneously acquired labs
#' @param time.diff.max The maximum time difference (in min) between successive
#'     simultaneous labs within the same encounter, to consider for this analysis.
#'     The default [Inf] allows all labs without a restriction. 
#' @param pt.size The point size on the Error Grid plot [Default: 0.3]
#' @param pt.alpha The point alpha value on the Error Grid plot [Default: 0.3]
#' @param perturb.amt A two-element list which defines the min and max amount 
#'     that each point is perturbed on the PERC_VALUE x-y plot. This is 
#'     necessary to avoid points falling on the exact edge of the grids, which
#'     causes double-counting within two error grid polygons. To avoid this, we
#'     perturb the point in both the x and y space by a random value, 
#'     uniformilly distributed between these two elements of the list.
#' @param to.print If True, prints results [Default]
#' @param to.return If True, returns results [Default]
#'
calculateChangeComparison <- function (paired.df, time.diff.max = Inf,
                                       pt.size = 0.3, pt.alpha = 0.3,
                                       perturb.amt = c(0.0001, 0.001),
                                       to.print = T, to.return = T) {
  
  #'
  #' Sub-function to define the underlying grid pts
  #' 
  makeBaseGrid <- function (g.size = 0.8, g.alpha = 0.5) {
    
    # Center Orange - Zone 1
    A.1 <- data.frame(
      X = c(-5., 5., 5., -5.),
      Y = c(-5., -5., 5., 5.))
    A.2 <- data.frame(
      X = c(5., 15., 15., 5.),
      Y = c(5., 5., 15., 15.))
    A.3 <- data.frame(
      X = c(-15., -5., -5., -15.),
      Y = c(-15., -15., -5., -5.))
      
    # Middle-outer Orange - Zone 1
    B.1 <- data.frame(
      X = c(15., 40., 40., 15.), 
      Y = c(15., 15., 40., 40.))
    B.2 <- data.frame(
      X = c(-40., -15., -15., -40.),
      Y = c(-40., -40., -15., -15.))

    # Outer-most Orange - Zone 1
    C.1 <- data.frame(
      X = c(40., 100., 100., 40.),
      Y = c(40., 40., 100., 100.))
    C.2 <- data.frame(
      X = c(-100., -40., -40., -100.),
      Y = c(-100., -100., -40., -40.))
    
    # Top Pink - Zone 2
    D.1 <- data.frame(
      X = c(5., 15., 15., 5.),
      Y = c(15., 15., 40., 40.))
    D.2 <- data.frame(
      X = c(15., 40., 40., 15.),
      Y = c(5., 5., 15., 15.))
    D.3 <- data.frame(
      X = c(5., 40., 40., 5.),
      Y = c(40., 40., 100., 100.))
    D.4 <- data.frame(
      X = c(40., 100., 100., 40.),
      Y = c(5., 5., 40., 40.))

    # Bottom Pink - Zone 2
    E.1 <- data.frame(
      X = c(-40., -15., -15., -40.),
      Y = c(-15., -15., -5., -5.))
    E.2 <- data.frame(
      X = c(-15., -5., -5., -15.),
      Y = c(-40., -40., -15., -15.))
    E.3 <- data.frame(
      X = c(-100., -40., -40., -100.),
      Y = c(-40., -40., -5., -5.))
    E.4 <- data.frame(
      X = c(-40., -5., -5., -40.),
      Y = c(-100., -100., -40., -40.))

    # Green - Zone 3
    G.1 <- data.frame(
      X = c(-5., 5., 5., -5.),
      Y = c(5., 5., 100., 100.))
    G.2 <- data.frame(
      X = c(5., 100., 100., 5.),
      Y = c(-5., -5., 5., 5.))
    G.3 <- data.frame(
      X = c(-5., 5., 5., -5.),
      Y = c(-100., -100., -5., -5.))
    G.4 <- data.frame(
      X = c(-100., -5., -5., -100.),
      Y = c(-5., -5., 5., 5.))

    # Blue - Zone 4
    H.1 <- data.frame(
      X = c(-100., -5., -5., -100.),
      Y = c(5., 5., 100., 100.))
    H.2 <- data.frame(
      X = c(5., 100., 100., 5.),
      Y = c(-100., -100., -5., -5.))
    
    # Generate grid
    p <- 
      ggplot() + 
      geom_abline(mapping = NULL, data = NULL,
                  slope = 1, intercept = 0, na.rm = FALSE, 
                  show.legend = NA, size = .5, color = '#666666', linetype = 'dashed') + 
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'orange', alpha = g.alpha, data = A.1) + 
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'orange', alpha = g.alpha, data = A.2) + 
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'orange', alpha = g.alpha, data = A.3) +       
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'orange', alpha = g.alpha, data = B.1) +
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'orange', alpha = g.alpha, data = B.2) +      
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'orange', alpha = g.alpha, data = C.1) +
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'orange', alpha = g.alpha, data = C.2) +
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'pink', alpha = g.alpha, data = D.1) + 
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'pink', alpha = g.alpha, data = D.2) +   
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'pink', alpha = g.alpha, data = D.3) + 
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'pink', alpha = g.alpha, data = D.4) +       
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'pink', alpha = g.alpha, data = E.1) + 
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'pink', alpha = g.alpha, data = E.2) +       
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'pink', alpha = g.alpha, data = E.3) + 
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'pink', alpha = g.alpha, data = E.4) +       
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'green', alpha = g.alpha, data = G.1) +
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'green', alpha = g.alpha, data = G.2) +
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'green', alpha = g.alpha, data = G.3) +      
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'green', alpha = g.alpha, data = G.4) +      
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'blue', alpha = g.alpha, data = H.1) +
      geom_polygon(aes(x = X, y = Y), size = g.size, color = 'black', linetype = 'dashed',
                   fill = 'blue', alpha = g.alpha, data = H.2) +      
      xlim(-100, 100) + ylim(-100, 100) +
      coord_cartesian(ylim = c(-100, 100), xlim = c(-100, 100)) + 
      scale_fill_distiller(palette = 4, direction = 1)

    return(list(
      vertices = list(
        A1 = A.1, A2 = A.2, A3 = A.3, 
        B1 = B.1, B2 = B.2, 
        C1 = C.1, C2 = C.2, 
        D1 = D.1, D2 = D.2, D3 = D.3, D4 = D.4, 
        E1 = E.1, E2 = E.2, E3 = E.3, E4 = E.4, 
        G1 = G.1, G2 = G.2, G3 = G.3, G4 = G.4, 
        H1 = H.1, H2 = H.2),
      p = p
    ))
  } # End of sub-function
  
  g <- makeBaseGrid()

  # Calculate absolute and percent change data frame
  change.df <-
    paired.df %>%
    dplyr::arrange(ENC_KEY, COLLECTED_DT.x) %>%
    dplyr::group_by(ENC_KEY) %>%
    dplyr::mutate(
      DIFF_ENC = ENC_KEY == lag(ENC_KEY),
      TIME_DIFF = as.numeric(
        COLLECTED_DT.x - lag(COLLECTED_DT.x),
        units = 'mins'
      ),      
      ABS_CHANGE_VAL.x = NUM_VAL.x - lag(NUM_VAL.x),
      ABS_CHANGE_VAL.y = NUM_VAL.y - lag(NUM_VAL.y),
      PERC_CHANGE_VAL.x = ABS_CHANGE_VAL.x / lag(NUM_VAL.x) * 100.,
      PERC_CHANGE_VAL.y = ABS_CHANGE_VAL.y / lag(NUM_VAL.y) * 100.
    ) %>%
    dplyr::filter(!is.na(DIFF_ENC)) %>%
    dplyr::filter(TIME_DIFF < time.diff.max) %>%
    dplyr::ungroup()
  
  # How many distinct X,Y percent-change pairs do we have?
  if (to.print) {
    cat(sprintf('Number of rows of `change.df` data frame: %d\n',
                nrow(change.df)))
    
    cat(sprintf('Number of distinct X,Y pairs of percent changes: %d\n',
                nrow(
                  change.df %>% 
                    dplyr::select(PERC_CHANGE_VAL.x, PERC_CHANGE_VAL.y) %>% 
                    dplyr::distinct())))
  }

  # Add % Change to Error Grid plot
  Error_Grid <- 
    g$p +
    geom_jitter(aes(x = PERC_CHANGE_VAL.x, y = PERC_CHANGE_VAL.y), data = change.df, 
                width = 0.3, height = 0.3, size = pt.size, alpha = pt.alpha) + 
    xlab('\u0394 Hgb from CBC (%)') + 
    ylab('\u0394 Hgb from BG (%)') + 
    theme_bw() + 
    theme(panel.grid.minor = element_blank()) + 
    theme(panel.background = element_rect(fill = "transparent", colour = NA),
          plot.background = element_rect(fill = "transparent", colour = NA))

  if (to.print)
    print(Error_Grid)

  perc.pts <- as.matrix(
    change.df %>% 
      dplyr::select(PERC_CHANGE_VAL.x, PERC_CHANGE_VAL.y) %>%
      dplyr::transmute(
        PERC_CHANGE_VAL.x = PERC_CHANGE_VAL.x + 
          runif(nrow(change.df), min = perturb.amt[1], max = perturb.amt[2]),
        PERC_CHANGE_VAL.y = PERC_CHANGE_VAL.y +
          runif(nrow(change.df), min = perturb.amt[1], max = perturb.amt[2])
      ))

  # Declare empty vector for point-in-range counts
  pinp <- vector(length = length(g$vertices))
  
  for (i in 1 : length(g$vertices)) {
    
    pinp[i] <- 
      sum(
        ptinpoly::pip2d(
          Vertices = as.matrix(g$vertices[[i]]), 
          Queries = perc.pts
        ) >= 0
      )
  }
  
  names(pinp) <- paste0(names(g$vertices), '.n')

  # Calculate the number of points in each "Zone"  
  Zone1 <- pinp['A1.n'] + pinp['A2.n'] + pinp['A3.n'] + 
    pinp['B1.n'] + pinp['B2.n'] + pinp['C1.n'] + pinp['C2.n']
  Zone2 <- pinp['D1.n'] + pinp['D2.n'] + pinp['D3.n'] + pinp['D4.n'] +
    pinp['E1.n'] + pinp['E2.n'] + pinp['E3.n'] + pinp['E4.n']
  Zone3 <- pinp['G1.n'] + pinp['G2.n'] + pinp['G3.n'] + pinp['G4.n']
  Zone4 <- pinp['H1.n'] + pinp['H2.n']

  if (to.print) {
    cat(sprintf('Sum of all zones: %d\n',
                Zone1 + Zone2 + Zone3 + Zone4))
    
    cat(sprintf(paste0('Zone 1: %d (%0.2f %%)\n',
                       'Zone 2: %d (%0.2f %%)\n',
                       'Zone 3: %d (%0.2f %%)\n',
                       'Zone 4: %d (%0.2f %%)\n'),
                Zone1, Zone1 / sum(pinp) * 100.,
                Zone2, Zone2 / sum(pinp) * 100.,
                Zone3, Zone3 / sum(pinp) * 100.,
                Zone4, Zone4 / sum(pinp) * 100.))
  }
  
  # Return
  if (to.return) 
    return(list(
      Error_Grid,
      pinp,
      list(Zone1, Zone2, Zone3, Zone4)
    ))
}
```

First we run across all repeated pairs (without restricting based on time):

```{r, fig.width = 6, fig.height = 6}
cbc.bg.all.pairs <-
  calculateChangeComparison(
    paired.df = cbc.bg,
    time.diff.max = Inf,
    to.print = T,
    to.return = T
  )
```

Then we restrict to our max time period as specified above in the parameter `time.diff.max`:

```{r, fig.width = 6, fig.height = 6}
cbc.bg.restrict.pairs <-
  calculateChangeComparison(
    paired.df = cbc.bg,
    time.diff.max = time.diff.max,
    to.print = T,
    to.return = T
  )
```

### Save Analyses

Now we save out all of the plots and calculations that we have completed:

```{r}
save(
  file = file.path(
    Sys.getenv('PICU_LAB_DATA_PATH'),
    paste0(
      Sys.getenv('PICU_LAB_SITE_NAME'),
      '_pri_cbc_bg_temporal_',
      run.date, '.rData'
    )
  ),
  primary.cutoff, time.diff.max,
  #cbc.bg, 
  res.cbc.bg.pairs,
  cbc.bg.all.pairs, cbc.bg.restrict.pairs
)
```

```{r, echo=FALSE}
rm(cbc.bg, res.cbc.bg.pairs, cbc.bg.all.pairs, cbc.bg.restrict.pairs)
```

## CBC vs POC (iStat)

To run across different proc names, we first build a function which runs these analyses:

```{r}
#'
#' @title Run All Temporal
#' 
#' @description Runs through all temporal assessments, for sensitivity analysis
#' 
#' @param labs.df The original labs data frame
#' @param cohort.df The original cohort data frame
#' @param compare.PN The comparison PROC name (e.g. either `BG` or `ISTAT`)
#' @param time.diff The cutoff time difference (in minutes) for determining 
#'     whether labs are "simultaneous"
#' @param multi.per.pt If TRUE, allows all results from patients; 
#'     If FALSE, only the first (chronological) result from a patient is included
#' @param time.diff.max The filter for max time between successive paired labs
#' @param run.date A string representation of date for saving (format: %Y-%m-%d)
#' @param save.fn The file name (which will be concatenated with SITE and run.date), 
#'     or NA [Default] if we do not wish to save any results to a file
#'
runAllTemporal <- function (labs.df, cohort.df, compare.PN,
                            time.diff, multi.per.pt, time.diff.max,
                            run.date, save.fn = NA) {
  
  # Create the paired dataset
  paired.df <- createPairedDataset(
    labs.df = labs.df, 
    cohort.df = cohort.df,
    PN = c('CBC', compare.PN), 
    CN = 'Hgb',
    time.diff = time.diff,
    multi.per.pt = multi.per.pt
  )
  
  # Describe the repeated pairs
  describe.repeat.pairs <- 
    describeRepeatedPairs(
      paired.df = paired.df, 
      to.print = T, 
      to.return = T
    )
  
  # First compute Change Error Grid on all time pairs
  compare.all.pairs <-
    calculateChangeComparison(
      paired.df = paired.df,
      time.diff.max = Inf,
      to.print = T,
      to.return = T
    )
  
  # Then restrict to the time diff specified
  compare.restrict.pairs <-
    calculateChangeComparison(
      paired.df = paired.df,
      time.diff.max = time.diff.max,
      to.print = T,
      to.return = T
    )  
  
  # Save out?
  if (! any(is.na(save.fn)) ) {
    save(
      file = file.path(
        Sys.getenv('PICU_LAB_DATA_PATH'),
        paste0(
          Sys.getenv('PICU_LAB_SITE_NAME'),
          '_', save.fn, '_',
          run.date, '.rData'
        )
      ),
      time.diff, compare.PN, time.diff.max,
      paired.df, 
      describe.repeat.pairs,
      compare.all.pairs, compare.restrict.pairs
    )
  }
}
```


```{r, echo=FALSE, eval=FALSE}
# Test this function based on our prior (individual) computations
runAllTemporal(
  labs.df,
  cohort.df, 
  compare.PN = 'BG',
  time.diff = primary.cutoff,
  multi.per.pt = T,
  time.diff.max = time.diff.max,
  run.date = run.date,
  save.fn = NA
)
```

Now we run for the POC values using the primary cutoff, allowing all results per patient (if the PROC exists):

```{r}
if ('ISTAT' %in% unique(labs.df$PROC_NAME)) {
  
  runAllTemporal(
    labs.df,
    cohort.df, 
    compare.PN = 'ISTAT',
    time.diff = primary.cutoff,
    multi.per.pt = T,
    time.diff.max = time.diff.max,
    run.date = run.date,
    save.fn = 'pri_cbc_istat_temporal'
  )

}
```
